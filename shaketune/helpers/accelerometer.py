# Shake&Tune: 3D printer analysis tools
#
# Copyright (C) 2024 FÃ©lix Boisselier <felix@fboisselier.fr> (Frix_x on Discord)
# Licensed under the GNU General Public License v3.0 (GPL-3.0)
#
# File: accelerometer.py
# Description: Provides a custom and internal Shake&Tune Accelerometer helper that interfaces
#              with Klipper's accelerometer classes. It includes functions to start and stop
#              accelerometer measurements.
#              It also includes functions to load and save measurements from a file in a new
#              compressed format (.stdata) or from the legacy Klipper CSV files.


import os
import pickle
import time
from multiprocessing import Process
from pathlib import Path
from typing import List, Tuple, TypedDict

import numpy as np
import zstandard as zstd

from ..helpers.console_output import ConsoleOutput

Sample = Tuple[float, float, float, float]
SamplesList = List[Sample]


class Measurement(TypedDict):
    name: str
    samples: SamplesList


class MeasurementsManager:
    def __init__(self, klipper_reactor):
        self._reactor = klipper_reactor
        self.measurements: List[Measurement] = []
        self._write_process = None

    def add_measurement(self, name: str, samples: SamplesList = None):
        samples = samples if samples is not None else []
        self.measurements.append({'name': name, 'samples': samples})

    def get_measurements(self) -> List[Measurement]:
        return self.measurements

    def append_samples_to_last_measurement(self, additional_samples: SamplesList):
        try:
            self.measurements[-1]['samples'].extend(additional_samples)
        except IndexError as err:
            raise ValueError('no measurements available to append samples to.') from err

    def clear_measurements(self):
        self.measurements = []

    def save_stdata(self, filename: Path):
        self._write_process = Process(target=self._save_to_file, args=(filename,))
        self._write_process.daemon = False
        self._write_process.start()

    def _save_to_file(self, filename: Path):
        try:
            os.nice(19)
        except Exception:
            pass  # Ignore errors as it's not critical
        try:
            with open(filename, 'wb') as f:
                cctx = zstd.ZstdCompressor(level=3)
                with cctx.stream_writer(f) as compressor:
                    pickle.dump(self.measurements, compressor)
        except Exception as e:
            ConsoleOutput.print(f'Warning: unable to save the measurements to {filename}: {e}')

    def load_from_stdata(self, filename: Path) -> List[Measurement]:
        with open(filename, 'rb') as f:
            dctx = zstd.ZstdDecompressor()
            with dctx.stream_reader(f) as decompressor:
                self.measurements = pickle.load(decompressor)
        return self.measurements

    def load_from_csvs(self, klipper_CSVs: List[Path]) -> List[Measurement]:
        for logname in klipper_CSVs:
            try:
                if logname.suffix != '.csv':
                    ConsoleOutput.print(f'Warning: {logname} is not a CSV file. It will be ignored by Shake&Tune!')
                    continue
                with open(logname) as f:
                    header = None
                    for line in f:
                        cleaned_line = line.strip()
                        # Check for a PSD file generated by Klipper and raise a warning
                        if cleaned_line.startswith('#freq,psd_x,psd_y,psd_z,psd_xyz'):
                            ConsoleOutput.print(
                                f'Warning: {logname} does not contain raw Klipper accelerometer data. '
                                'Please use the official Klipper script to process it instead. '
                            )
                            continue
                        # Check for the expected legacy header used in Shake&Tune (raw accelerometer data from Klipper)
                        elif cleaned_line.startswith('#time,accel_x,accel_y,accel_z'):
                            header = cleaned_line
                            break
                    if not header:
                        ConsoleOutput.print(
                            f"Warning: file {logname} doesn't seem to be a Klipper raw accelerometer data file. "
                            f"Expected '#time,accel_x,accel_y,accel_z', but got '{header.strip()}'. "
                            'This file will be ignored by Shake&Tune!'
                        )
                        continue
                    # If we have the correct raw data header, proceed to load the data
                    data = np.loadtxt(logname, comments='#', delimiter=',', skiprows=1)
                    if data.ndim == 1 or data.shape[1] != 4:
                        ConsoleOutput.print(
                            f'Warning: {logname} does not have the correct data format; expected 4 columns. '
                            'It will be ignored by Shake&Tune!'
                        )
                        continue

                    # Add the parsed klipper raw accelerometer data to Shake&Tune measurements object
                    samples = [tuple(row) for row in data]
                    self.add_measurement(name=logname.stem, samples=samples)
            except Exception as err:
                ConsoleOutput.print(f'Error while reading {logname}: {err}. It will be ignored by Shake&Tune!')
                continue

        return self.measurements

    def wait_for_file_writes(self, timeout: int = 20):
        if self._write_process is None:
            return  # No file write is pending

        eventtime = self._reactor.monotonic()
        endtime = eventtime + timeout
        complete = False

        while eventtime < endtime:
            eventtime = self._reactor.pause(eventtime + 0.05)
            if not self._write_process.is_alive():
                complete = True
                break

        if not complete:
            raise TimeoutError(
                'Shake&Tune was unable to write the accelerometer data into the archive file. '
                'This might be due to a slow SD card or a busy or full filesystem.'
            )

        self._write_process = None


class Accelerometer:
    def __init__(self, klipper_accelerometer, klipper_reactor):
        self._k_accelerometer = klipper_accelerometer
        self._reactor = klipper_reactor
        self._bg_client = None
        self._measurements_manager: MeasurementsManager = None

    @staticmethod
    def find_axis_accelerometer(printer, axis: str = 'xy'):
        accel_chip_names = printer.lookup_object('resonance_tester').accel_chip_names
        for chip_axis, chip_name in accel_chip_names:
            if axis in {'x', 'y'} and chip_axis == 'xy':
                return chip_name
            elif chip_axis == axis:
                return chip_name
        return None

    def start_recording(
        self, measurements_manager: MeasurementsManager = None, name: str = None, append_time: bool = True
    ):
        if measurements_manager is None:
            measurements_manager = MeasurementsManager(self._reactor)

        if self._bg_client is None:
            self._bg_client = self._k_accelerometer.start_internal_client()

            timestamp = time.strftime('%Y%m%d_%H%M%S')
            if name is None:
                name = timestamp
            elif append_time:
                name += f'_{timestamp}'

            if not name.replace('-', '').replace('_', '').isalnum():
                raise ValueError('invalid measurement name!')

            self._measurements_manager = measurements_manager
            self._measurements_manager.add_measurement(name=name)
        else:
            raise ValueError('Recording already started!')

    def stop_recording(self, timeout: int = 20) -> MeasurementsManager:
        if self._bg_client is None:
            ConsoleOutput.print('Warning: no recording to stop!')
            return None

        # Move sample retrieval and processing to a sub-process to reduce Klipper's main process load
        offload_process = Process(target=self._retrieve_and_process_samples)
        offload_process.start()

        eventtime = self._reactor.monotonic()
        endtime = eventtime + timeout
        complete = False
        while eventtime < endtime:
            eventtime = self._reactor.pause(eventtime + 0.05)
            if not offload_process.is_alive():
                complete = True
                break

        if not complete:
            raise TimeoutError(
                'Shake&Tune was unable to retrieve the accelerometer '
                'data and process it within the specified timeout!'
            )

        m_manager = self._measurements_manager
        self._measurements_manager = None

        return m_manager

    def _retrieve_and_process_samples(self):
        bg_client = self._bg_client
        self._bg_client = None
        bg_client.finish_measurements()

        samples = bg_client.samples or bg_client.get_samples()
        self._measurements_manager.append_samples_to_last_measurement(samples)
